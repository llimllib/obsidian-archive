https://matthewbutterick.com/chron/will-ai-obliterate-the-rule-of-law.html

> the core objec­tion is that so far, many gener­a­tive AI prod­ucts are **based on massive viola­tions of law**. If gener­a­tive AI compa­nies want to compete against human artists by legal means—they’re welcome to do so. But in many cases, that’s not what they’ve chosen. As a profes­sional artist, I’m not opposed to advance­ments in tech­nology; I’m opposed to viola­tions of the law.

> ...machines often have “free rein” legally. This axiom made sense when a machine was primarily under­stood as a tool wielded by a human. This distinc­tion has gotten murkier, however, as machines have moved into roles tradi­tion­ally reserved to human judg­ment.

> ...by dele­gating reading to a legally imper­vious machine—the “literate robot”—human actors avoid the usual legal scrutiny that would apply to their actions. In so doing, copy­right law is essen­tially neutral­ized. He fore­sees this remaining a tremen­dous incen­tive for humans to “outsource” reading to machines that are not treated as legally culpable agents. Even to the point of anni­hi­lating human reading alto­gether.

> ...If AI compa­nies are allowed to market AI systems that are essen­tially [black boxes](https://jolt.law.harvard.edu/assets/articlePDFs/v31/The-Artificial-Intelligence-Black-Box-and-the-Failure-of-Intent-and-Causation-Yavar-Bathaee.pdf), they could become the ulti­mate ends-justify-the-means devices. Before too long, we will not dele­gate deci­sions to AI systems because they perform better. Rather, **we will dele­gate deci­sions to AI systems because they can get away with every­thing that we can’t**. You’ve heard of money laun­dering? This is human-behavior laun­dering. At last—plau­sible deni­a­bility for every­thing.